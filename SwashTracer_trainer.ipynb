{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell to load training images, it will take about 2 minutes for the dataset used in the thesis. Then run the second cell to train a CNN model. The third cell can be run without the first and second cell run, and is used to re-evaluate any previously trained model on the test dataset.\n",
    "\n",
    "You will need the following folders and files in the working directory for this to work:\n",
    "- test_timestacks/\n",
    "- training_timestack_snapshots/\n",
    "- model folder (if testing a previously trained model)\n",
    "\n",
    "Make sure you rename the tf_model_version when you want to train a different model, if the same name is used it will overwrite the previous model trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# set the image size you want as input to the model\n",
    "IMG_SIZE = 64\n",
    "IMG_SIZE_WID = 64\n",
    "training_folder = \"training_timestack_snapshots\"\n",
    "\n",
    "# function to evaluate a model on the test timestacks\n",
    "def compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, \n",
    "                      IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, exe_value):\n",
    "    \n",
    "    folder_name = \"test_timestacks/\"\n",
    "    \n",
    "    uprush_width = max_uprush - min_uprush\n",
    "    \n",
    "    # add % to min and max uprush\n",
    "    min_uprush = int(min_uprush - uprush_width*(exc_value/200))\n",
    "    max_uprush = int(max_uprush + uprush_width*(exc_value/200))\n",
    "    \n",
    "    # add % to height of two peaks\n",
    "    height_of_two_peaks = int(height_of_two_peaks*(1 + eve_value/100))\n",
    "    \n",
    "    timestack = cv2.imread(folder_name + timestack_name)\n",
    "    timestack_focus = timestack[:, min_uprush:max_uprush]\n",
    "    timestack_labelled = cv2.imread(folder_name + timestack_name + \"_output.png\")\n",
    "    timestack_annotated = timestack_labelled.copy()\n",
    "    \n",
    "    padding = height_of_two_peaks\n",
    "    height, width, _ = timestack.shape\n",
    "    width = max_uprush - min_uprush\n",
    "    timestack_count = 0\n",
    "\n",
    "    tf_images = []\n",
    "    tf_model_xc = tf.keras.models.load_model(tf_model_version + \".model\")\n",
    "\n",
    "    vertical_coordinates = []\n",
    "    horizontal_coordinates = []\n",
    "    tf_images_list = []\n",
    "    for i in range(0, int((height - padding)), 1):\n",
    "\n",
    "        # get the small section of the image for the horizontal position i\n",
    "        timestack_snapshot = timestack_focus[i:i + padding, :]\n",
    "        \n",
    "        # classify the timestack snapshot through the convolutional neural network for x coordinate\n",
    "        tf_images = cv2.resize(timestack_snapshot, (IMG_SIZE_WID, IMG_SIZE))\n",
    "        tf_images_list.append(tf_images)\n",
    "    \n",
    "    tf_images_list = np.array(tf_images_list)\n",
    "    tf_images_list = tf.keras.utils.normalize(tf_images_list, axis=1)\n",
    "    tf_images_list = tf_images_list.reshape(-1, IMG_SIZE_WID, IMG_SIZE, 3)\n",
    "    \n",
    "    predictions = tf_model_xc.predict([tf_images_list])\n",
    "    \n",
    "    for i in range(0, int((height - padding)), 1):\n",
    "        \n",
    "        horizontal_coordinate = i + int(padding/2)      \n",
    "        vertical_coordinate = int((predictions[i][0])*width) + min_uprush\n",
    "        #vertical_coordinate = int(min_uprush + width/2) # use this line for straight baseline model calculation\n",
    "        \n",
    "        cv2.circle(timestack_annotated, (vertical_coordinate, horizontal_coordinate), radius=1, color=[255, 0, 0])\n",
    "        vertical_coordinates.append(vertical_coordinate)\n",
    "        horizontal_coordinates.append(horizontal_coordinate)\n",
    "        timestack_count = timestack_count + 1\n",
    "            \n",
    "    # get csv values from labelled timestack\n",
    "    manual_csv_points_filename = \"runup_data_test\" + timestack_name + \".csv\"\n",
    "    x_vals = []\n",
    "    t_vals = []\n",
    "    minima_test = []\n",
    "    maxima_test = []\n",
    "    with open(folder_name + manual_csv_points_filename, newline='') as csvfile:\n",
    "        points_reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        initial_row = 5\n",
    "        initial_row_counter = 0\n",
    "        for row in points_reader:\n",
    "            if initial_row_counter > initial_row:\n",
    "                rows = row[0].split(',')\n",
    "                x_vals.append( int(rows[0][1:-1]) )\n",
    "                t_vals.append( int(rows[1][1:-1]) )\n",
    "                # also extract min and max values\n",
    "                minima_test.append( int(rows[2][1:-1]) )\n",
    "                maxima_test.append( int(rows[3][1:-1]) )\n",
    "                \n",
    "            initial_row_counter = initial_row_counter + 1\n",
    "\n",
    "    full_stack_window = \"timestack_annotated\"\n",
    "\n",
    "    # find MSE for evey row\n",
    "    SE = []\n",
    "    minima_maxima_test_coords = []\n",
    "    for i in range(0, len(t_vals), 1):\n",
    "        # make sure the comparison values line up correctly\n",
    "        index_matching = np.where(np.array(horizontal_coordinates) == t_vals[i])\n",
    "        \n",
    "        # ensure prediction and manual points are both present\n",
    "        if len(index_matching[0]) < 1:\n",
    "            continue\n",
    "        \n",
    "        vertical_coordinate_matching = vertical_coordinates[ index_matching[0][0] ]\n",
    "        SE.append( (100*(x_vals[i] - vertical_coordinate_matching)/(uprush_width))**2 )\n",
    "        \n",
    "        # find minima and maxima values for predicted values\n",
    "        if minima_test[i] == 1:\n",
    "            minima_maxima_test_coords.append([x_vals[i], t_vals[i], -1])\n",
    "        elif maxima_test[i] == 1:\n",
    "            minima_maxima_test_coords.append([x_vals[i], t_vals[i], 1])\n",
    "    \n",
    "    RMSE = (np.mean(SE))**0.5\n",
    "    \n",
    "    SE_min = []\n",
    "    SE_max = []\n",
    "    # for each minima or maxima values excluding first and last value\n",
    "    for i in range(1, len(minima_maxima_test_coords)-1, 1):\n",
    "        t_limit_1 = minima_maxima_test_coords[i-1][1] + (minima_maxima_test_coords[i][1] - minima_maxima_test_coords[i-1][1])/2\n",
    "        t_limit_2 = minima_maxima_test_coords[i][1] + (minima_maxima_test_coords[i+1][1] - minima_maxima_test_coords[i][1])/2\n",
    "        \n",
    "        # between the two time limits, find the minimum predicted value\n",
    "        if minima_maxima_test_coords[i][2] == -1:\n",
    "            \n",
    "            indxs = np.where(np.logical_and(np.array(horizontal_coordinates) > t_limit_1, \n",
    "                                            np.array(horizontal_coordinates) < t_limit_2))\n",
    "            pred_min_x = np.min(np.array(vertical_coordinates)[indxs])\n",
    "            pred_min_t_ind = np.argmin(np.array(vertical_coordinates)[indxs])\n",
    "            pred_min_t = horizontal_coordinates[indxs[0][pred_min_t_ind]]\n",
    "\n",
    "            # plot on annotated image\n",
    "            cv2.circle(timestack_annotated, (minima_maxima_test_coords[i][0], minima_maxima_test_coords[i][1]), \n",
    "                       radius=1, color=[0, 255, 150])\n",
    "            cv2.circle(timestack_annotated, (pred_min_x, pred_min_t), radius=1, color=[255, 255, 0])\n",
    "            \n",
    "            SE_min.append( (100*(minima_maxima_test_coords[i][0] - pred_min_x)/(uprush_width))**2 )\n",
    "            \n",
    "        # between the two time limits, find the maximum predicted value\n",
    "        elif minima_maxima_test_coords[i][2] == 1:\n",
    "            \n",
    "            indxs = np.where(np.logical_and(np.array(horizontal_coordinates) > t_limit_1, \n",
    "                                            np.array(horizontal_coordinates) < t_limit_2))\n",
    "            pred_max_x = np.max(np.array(vertical_coordinates)[indxs])\n",
    "            pred_max_t_ind = np.argmax(np.array(vertical_coordinates)[indxs])\n",
    "            pred_max_t = horizontal_coordinates[indxs[0][pred_max_t_ind]]\n",
    "            \n",
    "            # plot on annotated image\n",
    "            cv2.circle(timestack_annotated, (minima_maxima_test_coords[i][0], minima_maxima_test_coords[i][1]), \n",
    "                       radius=1, color=[0, 255, 150])\n",
    "            cv2.circle(timestack_annotated, (pred_max_x, pred_max_t), radius=1, color=[255, 255, 0])\n",
    "            \n",
    "            SE_max.append( (100*(minima_maxima_test_coords[i][0] - pred_max_x)/(uprush_width))**2 )\n",
    "    \n",
    "    # get RMSE between min pairs and max pairs normalised by the range\n",
    "    RMSE_min = (np.mean(SE_min))**0.5\n",
    "    RMSE_max = (np.mean(SE_max))**0.5\n",
    "    \n",
    "    # save the image\n",
    "    print(\"saving image\")\n",
    "    cv2.imwrite(\"annotated_runup_timestack_\" + timestack_name + \"_\" + tf_model_version + \".png\", timestack_annotated)\n",
    "    \n",
    "    # save the data\n",
    "    print(\"Saving Data to csv file\")\n",
    "    # create csv file\n",
    "    output_data_name = \"runup_data_\" + timestack_name + \"_\" + tf_model_version + \".csv\"\n",
    "    with open(output_data_name, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows([[\"timestack shoreline coordinates\"]])\n",
    "\n",
    "    with open(output_data_name, 'a', newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        time_row = list([\"time (horizontal coordinate)\"])\n",
    "        time_row.extend(horizontal_coordinates)\n",
    "        x_row = list([\"x (vertical coordinate)\"])\n",
    "        x_row.extend(vertical_coordinates)\n",
    "        writer.writerow(time_row)\n",
    "        writer.writerow(x_row)\n",
    "\n",
    "    csvFile.close()\n",
    "    \n",
    "    return RMSE, RMSE_min, RMSE_max\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%%% GET IMAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "data = []\n",
    "training_test_ratio = 0.85\n",
    "exc_value = 0 # % excursion range increase or decrease\n",
    "eve_value = 0 # % events increase or decrease\n",
    "\n",
    "# first get all images and label accordingly\n",
    "image_names = listdir(training_folder)\n",
    "for i in range(0, len(image_names), 1):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    image_i = cv2.imread(training_folder + \"/\" + image_names[i])\n",
    "    height, _, _ = image_i.shape\n",
    "    # below line takes 3/10ths from each side of 5 peaks to give 2 peaks.\n",
    "    # note that /4 was used for the final model analysed in the thesis\n",
    "    # but should have been /3.3. A model was run with /3.3 and the \n",
    "    # difference in performance was negligable.\n",
    "    image_i = image_i[int(height/3.3):int(height - height/3.3), :]\n",
    "    resized_image = cv2.resize(image_i, (IMG_SIZE_WID, IMG_SIZE))\n",
    "    resized_image_flipped = cv2.flip(resized_image, 0)\n",
    "    Xc = float(image_names[i][23:28])\n",
    "    data.append([resized_image, Xc])\n",
    "    data.append([resized_image_flipped, Xc])\n",
    "    \n",
    "# Randomize rows of data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Setup a training set and test set\n",
    "data_train = data[0:int(training_test_ratio*len(data))]\n",
    "data_test = data[int(training_test_ratio*len(data)):]\n",
    "\n",
    "# Split x data from y data\n",
    "x_train = np.array(list(map(list, zip(*data_train)))[0])\n",
    "y_train = np.array(list(map(list, zip(*data_train)))[1])\n",
    "\n",
    "# setup data for tensorflow\n",
    "x_test = np.array(list(map(list, zip(*data_test)))[0])\n",
    "y_test = np.array(list(map(list, zip(*data_test)))[1])\n",
    "\n",
    "# normalize input features (which are the pixel values)\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "# reshape for convolutional compatability\n",
    "x_train = x_train.reshape(-1, IMG_SIZE_WID, IMG_SIZE, 3)\n",
    "x_test = x_test.reshape(-1, IMG_SIZE_WID, IMG_SIZE, 3)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%%%%%%%%%%%%%%%%%%% MODEL SETUP AND TRAINING %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "epochs_no = 50\n",
    "batch_size_no = 512\n",
    "tf_model_version = \"_v1\"\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape = x_train.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2,2), padding=\"SAME\"))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2,2), padding=\"SAME\"))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2,2), padding=\"SAME\"))\n",
    "\n",
    "model.add(Conv2D(256, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(256, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=['mean_squared_error'])\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size_no, validation_split=0.1, epochs=epochs_no)\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%%% MODEL EVALUATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"training loss = \" + str(train_loss))\n",
    "print(\"val loss     = \" + str(val_loss))\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model.save(\"Timestack_Shoreline_Xc\" + tf_model_version + \".model\")\n",
    "\n",
    "error_print_list = []\n",
    "\n",
    "timestack_name = \"20101109084810_02_25ppm_test_s.png\"\n",
    "min_uprush = 296\n",
    "max_uprush = 744\n",
    "height_of_two_peaks = int(209*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       \"Timestack_Shoreline_Xc\" + tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"20101110094203_05_25ppm_test_s.png\"\n",
    "min_uprush = 93\n",
    "max_uprush = 546\n",
    "height_of_two_peaks = int(280*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       \"Timestack_Shoreline_Xc\" + tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"20101109103953_08_25ppm_test_s.png\"\n",
    "min_uprush = 194\n",
    "max_uprush = 687\n",
    "height_of_two_peaks = int(238*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       \"Timestack_Shoreline_Xc\" + tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"20101111092821_01_25ppm_test_s.png\"\n",
    "min_uprush = 141\n",
    "max_uprush = 779\n",
    "height_of_two_peaks = int(353*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       \"Timestack_Shoreline_Xc\" + tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"moreton_12_test_s.png\"\n",
    "min_uprush = 117\n",
    "max_uprush = 235\n",
    "height_of_two_peaks = int(300*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       \"Timestack_Shoreline_Xc\" + tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"OneMile8_test_s.png\"\n",
    "min_uprush = 105\n",
    "max_uprush = 251\n",
    "height_of_two_peaks = int(258*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       \"Timestack_Shoreline_Xc\" + tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"FC4_test_s.png\"\n",
    "min_uprush = 51\n",
    "max_uprush = 205\n",
    "height_of_two_peaks = int(400*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       \"Timestack_Shoreline_Xc\" + tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"Werri31_test_s.png\"\n",
    "min_uprush = 71\n",
    "max_uprush = 203\n",
    "height_of_two_peaks = int(213*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       \"Timestack_Shoreline_Xc\" + tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "for err_val in error_print_list:\n",
    "    print(err_val)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell below can be used to re-evaluate any model without having to retrain a new model. You can also change the excursion and events values to perform some sensitivity analysis for user defined parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_version = \"Timestack_Shoreline_Xc\" + \"_v0\" # v0 is the model from the thesis\n",
    "IMG_SIZE = 64\n",
    "IMG_SIZE_WID = 64\n",
    "exc_value = 0 # % excursion range increase or decrease\n",
    "eve_value = 0 # % events increase or decrease\n",
    "\n",
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# function to evaluate a model on the test timestacks\n",
    "def compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, \n",
    "                      IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, exe_value):\n",
    "    \n",
    "    folder_name = \"test_timestacks/\"\n",
    "    \n",
    "    uprush_width = max_uprush - min_uprush\n",
    "    \n",
    "    # add % to min and max uprush\n",
    "    min_uprush = int(min_uprush - uprush_width*(exc_value/200))\n",
    "    max_uprush = int(max_uprush + uprush_width*(exc_value/200))\n",
    "    \n",
    "    # add % to height of two peaks\n",
    "    height_of_two_peaks = int(height_of_two_peaks*(1 + eve_value/100))\n",
    "    \n",
    "    timestack = cv2.imread(folder_name + timestack_name)\n",
    "    timestack_focus = timestack[:, min_uprush:max_uprush]\n",
    "    timestack_labelled = cv2.imread(folder_name + timestack_name + \"_output.png\")\n",
    "    timestack_annotated = timestack_labelled.copy()\n",
    "    \n",
    "    padding = height_of_two_peaks\n",
    "    height, width, _ = timestack.shape\n",
    "    width = max_uprush - min_uprush\n",
    "    timestack_count = 0\n",
    "\n",
    "    tf_images = []\n",
    "    tf_model_xc = tf.keras.models.load_model(tf_model_version + \".model\")\n",
    "\n",
    "    vertical_coordinates = []\n",
    "    horizontal_coordinates = []\n",
    "    tf_images_list = []\n",
    "    for i in range(0, int((height - padding)), 1):\n",
    "\n",
    "        # get the small section of the image for the horizontal position i\n",
    "        timestack_snapshot = timestack_focus[i:i + padding, :]\n",
    "        \n",
    "        # classify the timestack snapshot through the convolutional neural network for x coordinate\n",
    "        tf_images = cv2.resize(timestack_snapshot, (IMG_SIZE_WID, IMG_SIZE))\n",
    "        tf_images_list.append(tf_images)\n",
    "    \n",
    "    tf_images_list = np.array(tf_images_list)\n",
    "    tf_images_list = tf.keras.utils.normalize(tf_images_list, axis=1)\n",
    "    tf_images_list = tf_images_list.reshape(-1, IMG_SIZE_WID, IMG_SIZE, 3)\n",
    "    \n",
    "    predictions = tf_model_xc.predict([tf_images_list])\n",
    "    \n",
    "    for i in range(0, int((height - padding)), 1):\n",
    "        \n",
    "        horizontal_coordinate = i + int(padding/2)      \n",
    "        vertical_coordinate = int((predictions[i][0])*width) + min_uprush\n",
    "        #vertical_coordinate = int(min_uprush + width/2) # use this line for straight baseline model calculation\n",
    "        \n",
    "        cv2.circle(timestack_annotated, (vertical_coordinate, horizontal_coordinate), radius=1, color=[255, 0, 0])\n",
    "        vertical_coordinates.append(vertical_coordinate)\n",
    "        horizontal_coordinates.append(horizontal_coordinate)\n",
    "        timestack_count = timestack_count + 1\n",
    "            \n",
    "    # get csv values from labelled timestack\n",
    "    manual_csv_points_filename = \"runup_data_test\" + timestack_name + \".csv\"\n",
    "    x_vals = []\n",
    "    t_vals = []\n",
    "    minima_test = []\n",
    "    maxima_test = []\n",
    "    with open(folder_name + manual_csv_points_filename, newline='') as csvfile:\n",
    "        points_reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        initial_row = 5\n",
    "        initial_row_counter = 0\n",
    "        for row in points_reader:\n",
    "            if initial_row_counter > initial_row:\n",
    "                rows = row[0].split(',')\n",
    "                x_vals.append( int(rows[0][1:-1]) )\n",
    "                t_vals.append( int(rows[1][1:-1]) )\n",
    "                # also extract min and max values\n",
    "                minima_test.append( int(rows[2][1:-1]) )\n",
    "                maxima_test.append( int(rows[3][1:-1]) )\n",
    "                \n",
    "            initial_row_counter = initial_row_counter + 1\n",
    "\n",
    "    full_stack_window = \"timestack_annotated\"\n",
    "\n",
    "    # find MSE for evey row\n",
    "    SE = []\n",
    "    minima_maxima_test_coords = []\n",
    "    for i in range(0, len(t_vals), 1):\n",
    "        # make sure the comparison values line up correctly\n",
    "        index_matching = np.where(np.array(horizontal_coordinates) == t_vals[i])\n",
    "        \n",
    "        # ensure prediction and manual points are both present\n",
    "        if len(index_matching[0]) < 1:\n",
    "            continue\n",
    "        \n",
    "        vertical_coordinate_matching = vertical_coordinates[ index_matching[0][0] ]\n",
    "        SE.append( (100*(x_vals[i] - vertical_coordinate_matching)/(uprush_width))**2 )\n",
    "        \n",
    "        # find minima and maxima values for predicted values\n",
    "        if minima_test[i] == 1:\n",
    "            minima_maxima_test_coords.append([x_vals[i], t_vals[i], -1])\n",
    "        elif maxima_test[i] == 1:\n",
    "            minima_maxima_test_coords.append([x_vals[i], t_vals[i], 1])\n",
    "    \n",
    "    RMSE = (np.mean(SE))**0.5\n",
    "    \n",
    "    SE_min = []\n",
    "    SE_max = []\n",
    "    # for each minima or maxima values excluding first and last value\n",
    "    for i in range(1, len(minima_maxima_test_coords)-1, 1):\n",
    "        t_limit_1 = minima_maxima_test_coords[i-1][1] + (minima_maxima_test_coords[i][1] - minima_maxima_test_coords[i-1][1])/2\n",
    "        t_limit_2 = minima_maxima_test_coords[i][1] + (minima_maxima_test_coords[i+1][1] - minima_maxima_test_coords[i][1])/2\n",
    "        \n",
    "        # between the two time limits, find the minimum predicted value\n",
    "        if minima_maxima_test_coords[i][2] == -1:\n",
    "            \n",
    "            indxs = np.where(np.logical_and(np.array(horizontal_coordinates) > t_limit_1, \n",
    "                                            np.array(horizontal_coordinates) < t_limit_2))\n",
    "            pred_min_x = np.min(np.array(vertical_coordinates)[indxs])\n",
    "            pred_min_t_ind = np.argmin(np.array(vertical_coordinates)[indxs])\n",
    "            pred_min_t = horizontal_coordinates[indxs[0][pred_min_t_ind]]\n",
    "\n",
    "            # plot on annotated image\n",
    "            cv2.circle(timestack_annotated, (minima_maxima_test_coords[i][0], minima_maxima_test_coords[i][1]), \n",
    "                       radius=1, color=[0, 255, 150])\n",
    "            cv2.circle(timestack_annotated, (pred_min_x, pred_min_t), radius=1, color=[255, 255, 0])\n",
    "            \n",
    "            SE_min.append( (100*(minima_maxima_test_coords[i][0] - pred_min_x)/(uprush_width))**2 )\n",
    "            \n",
    "        # between the two time limits, find the maximum predicted value\n",
    "        elif minima_maxima_test_coords[i][2] == 1:\n",
    "            \n",
    "            indxs = np.where(np.logical_and(np.array(horizontal_coordinates) > t_limit_1, \n",
    "                                            np.array(horizontal_coordinates) < t_limit_2))\n",
    "            pred_max_x = np.max(np.array(vertical_coordinates)[indxs])\n",
    "            pred_max_t_ind = np.argmax(np.array(vertical_coordinates)[indxs])\n",
    "            pred_max_t = horizontal_coordinates[indxs[0][pred_max_t_ind]]\n",
    "            \n",
    "            # plot on annotated image\n",
    "            cv2.circle(timestack_annotated, (minima_maxima_test_coords[i][0], minima_maxima_test_coords[i][1]), \n",
    "                       radius=1, color=[0, 255, 150])\n",
    "            cv2.circle(timestack_annotated, (pred_max_x, pred_max_t), radius=1, color=[255, 255, 0])\n",
    "            \n",
    "            SE_max.append( (100*(minima_maxima_test_coords[i][0] - pred_max_x)/(uprush_width))**2 )\n",
    "    \n",
    "    # get RMSE between min pairs and max pairs normalised by the range\n",
    "    RMSE_min = (np.mean(SE_min))**0.5\n",
    "    RMSE_max = (np.mean(SE_max))**0.5\n",
    "    \n",
    "    # save the image\n",
    "    print(\"saving image\")\n",
    "    cv2.imwrite(\"annotated_runup_timestack_\" + timestack_name + \"_\" + tf_model_version + \".png\", timestack_annotated)\n",
    "    \n",
    "    # save the data\n",
    "    print(\"Saving Data to csv file\")\n",
    "    # create csv file\n",
    "    output_data_name = \"runup_data_\" + timestack_name + \"_\" + tf_model_version + \".csv\"\n",
    "    with open(output_data_name, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows([[\"timestack shoreline coordinates\"]])\n",
    "\n",
    "    with open(output_data_name, 'a', newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        time_row = list([\"time (horizontal coordinate)\"])\n",
    "        time_row.extend(horizontal_coordinates)\n",
    "        x_row = list([\"x (vertical coordinate)\"])\n",
    "        x_row.extend(vertical_coordinates)\n",
    "        writer.writerow(time_row)\n",
    "        writer.writerow(x_row)\n",
    "\n",
    "    csvFile.close()\n",
    "    \n",
    "    return RMSE, RMSE_min, RMSE_max\n",
    "\n",
    "new_model = tf.keras.models.load_model(tf_model_version + \".model\")\n",
    "new_model.summary()\n",
    "\n",
    "error_print_list = []\n",
    "\n",
    "timestack_name = \"20101109084810_02_25ppm_test_s.png\"\n",
    "min_uprush = 296\n",
    "max_uprush = 744\n",
    "height_of_two_peaks = int(209*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"20101110094203_05_25ppm_test_s.png\"\n",
    "min_uprush = 93\n",
    "max_uprush = 546\n",
    "height_of_two_peaks = int(280*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"20101109103953_08_25ppm_test_s.png\"\n",
    "min_uprush = 194\n",
    "max_uprush = 687\n",
    "height_of_two_peaks = int(238*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"20101111092821_01_25ppm_test_s.png\"\n",
    "min_uprush = 141\n",
    "max_uprush = 779\n",
    "height_of_two_peaks = int(353*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \" is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"moreton_12_test_s.png\"\n",
    "min_uprush = 117\n",
    "max_uprush = 235\n",
    "height_of_two_peaks = int(300*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \"              is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"OneMile8_test_s.png\"\n",
    "min_uprush = 105\n",
    "max_uprush = 251\n",
    "height_of_two_peaks = int(258*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \"                is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"FC4_test_s.png\"\n",
    "min_uprush = 51\n",
    "max_uprush = 205\n",
    "height_of_two_peaks = int(400*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \"                     is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "timestack_name = \"Werri31_test_s.png\"\n",
    "min_uprush = 71\n",
    "max_uprush = 203\n",
    "height_of_two_peaks = int(213*2/5)\n",
    "RMSE, RMSE_min, RMSE_max = compare_shoreline(min_uprush, max_uprush, \n",
    "                                       tf_model_version, \n",
    "                                       IMG_SIZE, IMG_SIZE_WID, timestack_name, height_of_two_peaks, exc_value, eve_value)\n",
    "\n",
    "error_print_list.append(\"RMSE for \" + timestack_name + \"                 is \" + str(round(RMSE, 2)) + \"%, minima RMSE = \" + \n",
    "                        str(round(RMSE_min, 2)) + \"%, maxima RMSE = \" + str(round(RMSE_max, 2)) + \"%\")\n",
    "\n",
    "for err_val in error_print_list:\n",
    "    print(err_val)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
